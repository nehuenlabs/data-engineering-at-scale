# GuÃ­a de Ejercicios â€” Cap.01: De Concurrencia a Datos Distribuidos

> Este capÃ­tulo es el puente entre el repositorio de concurrencia y este.
> No tiene cÃ³digo de Spark ni de Kafka â€” tiene el modelo mental que hace
> que los siguientes 19 capÃ­tulos tengan sentido.
>
> Si vienes del repo de concurrencia, este capÃ­tulo te mostrarÃ¡ quÃ©
> cambia y quÃ© se conserva. Si no, te darÃ¡ el contexto mÃ­nimo necesario.

---

## El cambio de perspectiva

En el repositorio de concurrencia, el problema central era:

> *Tengo mÃºltiples unidades de ejecuciÃ³n (goroutines, threads) que
> necesitan coordinarse. Â¿CÃ³mo evito races, deadlocks, y starvation?*

En este repositorio, el problema es diferente:

> *Tengo mÃ¡s datos de los que caben en una mÃ¡quina, o datos que llegan
> mÃ¡s rÃ¡pido de lo que puedo procesar. Â¿CÃ³mo proceso todo sin perder
> correcciÃ³n ni rendimiento?*

Son problemas relacionados pero no iguales. La diferencia mÃ¡s importante:

```
Concurrencia (repo anterior):
  TÃº controlas el paralelismo.
  Decides cuÃ¡ntos goroutines, cuÃ¡ndo se comunican, cÃ³mo se sincronizan.
  Los bugs son: races, deadlocks, starvation.

Data engineering a escala (este repo):
  El framework controla el paralelismo.
  TÃº describes QUÃ‰ procesar; el framework decide CÃ“MO.
  Los bugs son: skew, shuffles innecesarios, estado que crece sin lÃ­mite.
```

Esta inversiÃ³n de control es el concepto mÃ¡s importante del capÃ­tulo.
Ignorarla â€” e intentar controlar el paralelismo de Spark manualmente â€”
es el origen de la mayorÃ­a de los problemas de rendimiento que verÃ¡s.

---

## Por quÃ© el paralelismo es diferente a escala

Considera este programa en Go que suma una lista de nÃºmeros:

```go
// Concurrencia manual: tÃº decides cÃ³mo particionar y combinar
func sumarParalelo(nums []int, goroutines int) int {
    tamaÃ±o := len(nums) / goroutines
    resultados := make(chan int, goroutines)

    for i := 0; i < goroutines; i++ {
        inicio := i * tamaÃ±o
        fin := inicio + tamaÃ±o
        go func(segmento []int) {
            suma := 0
            for _, n := range segmento { suma += n }
            resultados <- suma
        }(nums[inicio:fin])
    }

    total := 0
    for i := 0; i < goroutines; i++ { total += <-resultados }
    return total
}
```

Ahora el mismo problema en PySpark:

```python
# Paralelismo declarativo: describes quÃ©, el framework decide cÃ³mo
df = spark.read.parquet("s3://bucket/numeros/")
total = df.agg(F.sum("valor")).collect()[0][0]
```

En el cÃ³digo de Go, tÃº decides:
- CuÃ¡ntos goroutines (explÃ­cito: `goroutines`)
- CÃ³mo dividir el trabajo (explÃ­cito: `tamaÃ±o = len(nums) / goroutines`)
- CÃ³mo combinar los resultados (explÃ­cito: el canal)

En el cÃ³digo de Spark, Spark decide:
- CuÃ¡ntas tasks (basado en el nÃºmero de particiones del archivo)
- CÃ³mo dividir el trabajo (una task por particiÃ³n)
- CÃ³mo combinar los resultados (internamente, con un shuffle si es necesario)

Ninguno de los dos es "mejor" â€” son apropiados para contextos distintos.
Go es correcto para un array en memoria en un proceso. Spark es correcto
para datos en S3 distribuidos en cientos de archivos, procesados en
un cluster de 50 mÃ¡quinas.

---

## La tabla de correspondencias

Esta tabla aparece en el README y merece expandirse:

| Concepto en concurrencia | Equivalente en data engineering | Diferencia clave |
|---|---|---|
| Thread / Goroutine | Task de Spark, Flink operator | El framework los crea y gestiona, no tÃº |
| Canal de Go | Kafka topic, Beam PCollection | Puede ser persistente y distribuido |
| Mutex / Lock | OCC en Delta Lake | No bloquea â€” detecta conflictos al commitear |
| Race condition | Inconsistencia en replicaciÃ³n eventual | Se manifiesta en datos, no en crashes |
| Deadlock | Shuffle deadlock en Spark | Menos frecuente, pero ocurre |
| Goroutine leak | Consumer lag creciente en Kafka | El "leak" son mensajes sin procesar |
| Circuit breaker | Backpressure en streaming | Ralentiza el productor en lugar de fallar |
| Exactly-once | Exactly-once en Kafka/Flink | Mucho mÃ¡s difÃ­cil de garantizar |

---

## Tabla de contenidos

- [SecciÃ³n 1.1 â€” La inversiÃ³n de control](#secciÃ³n-11--la-inversiÃ³n-de-control)
- [SecciÃ³n 1.2 â€” El problema del tamaÃ±o: cuando los datos no caben](#secciÃ³n-12--el-problema-del-tamaÃ±o-cuando-los-datos-no-caben)
- [SecciÃ³n 1.3 â€” El problema del tiempo: cuando los datos no terminan](#secciÃ³n-13--el-problema-del-tiempo-cuando-los-datos-no-terminan)
- [SecciÃ³n 1.4 â€” El tradeoff central: latencia vs throughput](#secciÃ³n-14--el-tradeoff-central-latencia-vs-throughput)
- [SecciÃ³n 1.5 â€” El ecosistema: quÃ© herramienta para quÃ© problema](#secciÃ³n-15--el-ecosistema-quÃ©-herramienta-para-quÃ©-problema)

---

## SecciÃ³n 1.1 â€” La InversiÃ³n de Control

### Ejercicio 1.1.1 â€” Leer: el mismo algoritmo, dos paradigmas

**Tipo: Leer/comparar**

El algoritmo: contar las palabras mÃ¡s frecuentes en un corpus de texto.

**ImplementaciÃ³n 1 â€” concurrencia manual (Python con multiprocessing):**

```python
from multiprocessing import Pool
from collections import Counter
import os

def contar_en_archivo(ruta: str) -> Counter:
    with open(ruta) as f:
        return Counter(f.read().split())

def top_palabras_paralelo(directorio: str, top_n: int = 10) -> list:
    archivos = [
        os.path.join(directorio, f)
        for f in os.listdir(directorio)
        if f.endswith('.txt')
    ]

    # El programador decide: cuÃ¡ntos workers, cÃ³mo dividir, cÃ³mo combinar
    with Pool(processes=os.cpu_count()) as pool:
        conteos_por_archivo = pool.map(contar_en_archivo, archivos)

    total = Counter()
    for conteo in conteos_por_archivo:
        total.update(conteo)

    return total.most_common(top_n)
```

**ImplementaciÃ³n 2 â€” declarativa (PySpark):**

```python
from pyspark.sql import SparkSession
from pyspark.sql import functions as F

spark = SparkSession.builder.getOrCreate()

top_palabras = (spark
    .read.text("s3://bucket/corpus/*.txt")
    .select(F.explode(F.split("value", r"\s+")).alias("palabra"))
    .filter(F.col("palabra") != "")
    .groupBy("palabra")
    .count()
    .orderBy(F.col("count").desc())
    .limit(10)
)

top_palabras.show()
```

**Preguntas:**

1. En la implementaciÃ³n con `multiprocessing`, Â¿quiÃ©n decide cuÃ¡ntos workers?
   Â¿QuiÃ©n decide cÃ³mo dividir el trabajo entre ellos?

2. En la implementaciÃ³n con Spark, Â¿quiÃ©n decide cuÃ¡ntas tasks paralelas
   se ejecutan? Â¿Puedes verlo en el cÃ³digo?

3. La implementaciÃ³n con `multiprocessing` falla si el corpus no cabe
   en la memoria del proceso que llama a `pool.map`. Â¿Por quÃ©?
   Â¿Falla igual la implementaciÃ³n de Spark?

4. Si tienes 1,000 archivos de texto y 8 cores, Â¿cÃ³mo distribuye el trabajo
   cada implementaciÃ³n? Â¿CuÃ¡l es mÃ¡s eficiente?

5. Si un archivo tiene 100Ã— el tamaÃ±o de los demÃ¡s, Â¿cuÃ¡l implementaciÃ³n
   maneja mejor ese desbalance? Â¿Por quÃ©?

**Pista:** La pregunta 5 apunta al concepto de *data skew* que serÃ¡ central
en el Cap.04. Con `multiprocessing`, un archivo de 100Ã— el tamaÃ±o ocupa
un worker completo durante 100Ã— mÃ¡s tiempo â€” los otros 7 workers terminan
y esperan. Spark puede subdividir ese archivo en mÃºltiples particiones
(si el formato lo permite) y distribuir las particiones entre workers.

---

### Ejercicio 1.1.2 â€” Leer: quÃ© pierdes y quÃ© ganas con la inversiÃ³n de control

**Tipo: Analizar**

La inversiÃ³n de control tiene costos reales. No es solo una simplificaciÃ³n.

```python
# Lo que puedes hacer con multiprocessing que NO puedes con Spark:

# 1. Control fino del scheduling:
with Pool(8) as pool:
    # Primero procesar los archivos pequeÃ±os (para tener resultados rÃ¡pido)
    archivos_ordenados = sorted(archivos, key=os.path.getsize)
    resultados = pool.map(procesar, archivos_ordenados)

# 2. Estado compartido en memoria (con cuidado):
from multiprocessing import Manager
with Manager() as manager:
    cachÃ© = manager.dict()  # compartida entre workers
    pool.starmap(procesar_con_cache, [(archivo, cachÃ©) for archivo in archivos])

# 3. CancelaciÃ³n granular:
result = pool.apply_async(procesar_lento, [archivo])
try:
    resultado = result.get(timeout=5.0)  # cancelar si tarda mÃ¡s de 5s
except TimeoutError:
    pool.terminate()
```

```python
# Lo que Spark hace automÃ¡ticamente que multiprocessing NO hace:

# 1. Tolerancia a fallos:
# Si un worker de Spark falla a mitad de una task, Spark reintenta
# automÃ¡ticamente en otro worker. Con multiprocessing: excepciÃ³n, job muerto.

# 2. Escalar a mÃºltiples mÃ¡quinas:
# Spark distribuye las tasks en 50 mÃ¡quinas sin cambiar el cÃ³digo.
# multiprocessing: limitado a los cores de una sola mÃ¡quina.

# 3. Leer datos distribuidos:
# Spark lee directamente de S3, HDFS, Delta Lake con locality awareness.
# multiprocessing: necesitas que los datos estÃ©n en el sistema de archivos local.

# 4. OptimizaciÃ³n del plan:
# Spark puede reordenar operaciones, aplicar predicate pushdown,
# elegir el tipo de join Ã³ptimo.
# multiprocessing: tÃº eres el optimizador.
```

**Preguntas:**

1. Para cada uno de los tres ejemplos de "lo que puedes hacer con
   multiprocessing pero no con Spark", Â¿existe un equivalente en Spark?
   Si sÃ­, Â¿cÃ³mo se ve?

2. La "tolerancia a fallos" de Spark tiene un costo.
   Â¿CuÃ¡l es ese costo y cuÃ¡ndo es significativo?

3. Imagina que necesitas procesar 100 archivos de 1 GB cada uno.
   Tienes una mÃ¡quina con 32 GB de RAM y 16 cores.
   Â¿CuÃ¡l de los dos enfoques elegirÃ­a y por quÃ©?

4. Misma pregunta pero los archivos son 10,000 archivos de 10 GB cada uno,
   distribuidos en un cluster de 20 mÃ¡quinas.

5. Â¿En quÃ© escenario `multiprocessing` serÃ­a claramente la elecciÃ³n
   correcta sobre Spark, incluso si el dataset es grande?

**Pista:** Para la pregunta 5: cuando el costo de arrancar y coordinar
un cluster de Spark supera el beneficio del paralelismo. Un job que tarda
30 segundos en un laptop con `multiprocessing` puede tardar 2 minutos
en Spark solo por el overhead de arrancar el SparkSession, el scheduler,
y la coordinaciÃ³n. Para jobs frecuentes sobre datos pequeÃ±os o medianos
(< ~50 GB en una mÃ¡quina con suficiente RAM), `multiprocessing` o Polars
pueden ser mÃ¡s prÃ¡cticos.

---

### Ejercicio 1.1.3 â€” El modelo mental de la ejecuciÃ³n distribuida

**Tipo: Leer**

Antes de ver cÃ³digo de Spark o Flink, vale la pena tener el modelo mental
de cÃ³mo un framework distribuido ejecuta trabajo.

```
El modelo de tres capas:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TU CÃ“DIGO (el Driver)                                  â”‚
â”‚  Define el plan de trabajo.                             â”‚
â”‚  "Leer estos archivos, filtrar estas filas, agrupar     â”‚
â”‚   por esta columna, escribir aquÃ­."                     â”‚
â”‚  NO procesa datos â€” solo describe el trabajo.           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ plan de trabajo
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EL SCHEDULER (Spark Master / Flink JobManager)         â”‚
â”‚  Traduce el plan en tasks.                              â”‚
â”‚  Asigna tasks a workers considerando locality.          â”‚
â”‚  Reintenta tasks fallidas.                              â”‚
â”‚  Monitorea el progreso.                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ tasks asignadas
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LOS WORKERS (Spark Executors / Flink TaskManagers)     â”‚
â”‚  Ejecutan las tasks.                                    â”‚
â”‚  Leen datos (desde S3, HDFS, Kafka).                    â”‚
â”‚  Procesan y producen resultados parciales.              â”‚
â”‚  Comunican datos entre sÃ­ (shuffle).                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Preguntas:**

1. En el modelo de tres capas, Â¿quÃ© pasa si el Driver muere a mitad
   de un job? Â¿Y si muere un Worker?

2. "Locality awareness" significa que el scheduler intenta asignar
   una task al worker que tiene los datos mÃ¡s cerca.
   Â¿Por quÃ© esto importa en un cluster distribuido?

3. Â¿QuÃ© tipo de comunicaciÃ³n entre workers no puede evitarse en un
   GroupBy (aggregation)? Â¿Por quÃ©?

4. Si tienes 100 archivos de Parquet en S3 y 10 workers,
   Â¿cuÃ¡ntas tasks se crean para leer esos archivos?
   Â¿Depende de algo mÃ¡s que el nÃºmero de archivos?

5. El Driver "no procesa datos â€” solo describe el trabajo".
   Â¿QuÃ© pasa si haces `df.collect()` en el Driver?
   Â¿Viola esta propiedad?

**Pista:** Para la pregunta 4: el nÃºmero de tasks depende del nÃºmero de
particiones, no solo del nÃºmero de archivos. Un archivo de Parquet grande
puede dividirse en mÃºltiples particiones (tÃ­picamente de 128 MB cada una).
Un archivo de 10 GB â†’ ~80 tasks si el tamaÃ±o de particiÃ³n es 128 MB.
La "locality" en S3 es diferente a HDFS: en S3 los datos no tienen
una ubicaciÃ³n fÃ­sica fija, asÃ­ que la locality es menos relevante â€”
todos los workers tienen el mismo costo de acceso a S3.

---

### Ejercicio 1.1.4 â€” DiseÃ±ar: cuÃ¡ndo NO usar un framework distribuido

**Tipo: DiseÃ±ar**

El instinto de usar Spark para todo en data engineering es comprensible
pero costoso. Para cada caso, decidir si un framework distribuido
es necesario o si hay una soluciÃ³n mÃ¡s simple:

```
Caso 1:
  Dataset: 500 MB de CSV con datos de ventas mensuales.
  OperaciÃ³n: calcular el total de ventas por regiÃ³n.
  Frecuencia: una vez al mes, ejecutado en un laptop con 16 GB RAM.

Caso 2:
  Dataset: 50 TB de logs de acceso web, creciendo 100 GB/dÃ­a.
  OperaciÃ³n: contar URLs Ãºnicas visitadas en el Ãºltimo aÃ±o.
  Frecuencia: reporte diario, necesario en menos de 2 horas.

Caso 3:
  Dataset: 20 GB de datos de sensores IoT.
  OperaciÃ³n: detectar anomalÃ­as usando un modelo de ML ya entrenado.
  Frecuencia: cada hora, en una mÃ¡quina con 64 GB RAM y 32 cores.

Caso 4:
  Dataset: 200 GB de transacciones bancarias.
  OperaciÃ³n: join con una tabla de 1 GB de clientes,
             luego agregar por segmento de cliente.
  Frecuencia: cada noche.

Caso 5:
  Dataset: stream de eventos de clickstream, ~50,000 eventos/segundo.
  OperaciÃ³n: calcular el nÃºmero de usuarios activos en los Ãºltimos 5 minutos.
  Latencia requerida: resultado actualizado cada 10 segundos.
```

Para cada caso, indica:
- Herramienta recomendada (Polars, Pandas, Spark, Flink, otro)
- JustificaciÃ³n en tÃ©rminos de: tamaÃ±o del dato, frecuencia, latencia, equipo
- Costo aproximado de usar Spark vs la alternativa

**Pista:** La regla prÃ¡ctica para Spark: si el dato cabe en memoria de una
mÃ¡quina razonablemente equipada (digamos, 128 GB RAM), Polars o DuckDB
son frecuentemente mÃ¡s rÃ¡pidos y mÃ¡s simples. Spark paga dividendos cuando
los datos genuinamente no caben en una mÃ¡quina o cuando el cluster ya existe
y el overhead de arranque es amortizado por jobs frecuentes.

> ğŸ”— Ecosistema: DuckDB es otra herramienta relevante para el Caso 1 y 3 â€”
> un motor SQL analÃ­tico en memoria, sin cluster, extremadamente eficiente
> para datasets de hasta ~100 GB. No se cubre en profundidad en este repo
> pero vale tenerlo en el radar.

---

### Ejercicio 1.1.5 â€” Leer: el costo del overhead de coordinaciÃ³n

**Tipo: Medir/analizar**

El siguiente experimento mide el overhead de distintos frameworks
para el mismo job sobre distintos tamaÃ±os de datos:

```
Job: leer un archivo Parquet, filtrar filas donde monto > 100,
     agrupar por regiÃ³n, sumar montos.

Hardware: laptop, 16 GB RAM, 8 cores, SSD NVMe.

Resultados (tiempo en segundos):

TamaÃ±o    Pandas    Polars    Spark (local)    Spark (cluster 4 nodos)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
100 MB     0.8s      0.3s         8.2s               12.4s
1 GB       7.4s      1.9s        11.3s               14.1s
10 GB    OOM (*)    18.4s        42.1s               31.2s
100 GB     N/A       N/A        380s                 89s
1 TB       N/A       N/A         N/A                920s

(*) Pandas cargÃ³ el archivo completo en memoria y se quedÃ³ sin RAM
```

**Preguntas:**

1. Â¿Por quÃ© Spark local es mÃ¡s lento que Polars para 100 MB y 1 GB?
   Â¿QuÃ© explica los 8.2 segundos de Spark vs 0.3 de Polars para 100 MB?

2. Â¿A quÃ© tamaÃ±o de datos Spark cluster empieza a ser mÃ¡s rÃ¡pido
   que Polars (single-node)?

3. El Spark local para 100 GB tarda 380 segundos vs 89 segundos
   en el cluster de 4 nodos. Â¿El speedup es proporcional al nÃºmero de nodos?
   Â¿Por quÃ© no?

4. Â¿QuÃ© informaciÃ³n falta en esta tabla para tomar una decisiÃ³n
   de arquitectura completa?

5. Si el job se ejecuta 100 veces al dÃ­a sobre datos de 1 GB cada vez,
   Â¿quÃ© herramienta elegirÃ­as y por quÃ©?

**Pista:** El overhead de Spark para datos pequeÃ±os incluye:
arrancar la JVM (~1-2s), inicializar el SparkSession (~2-3s),
planificar el job, y comunicar el plan a los executors.
Este overhead es fijo â€” no escala con el tamaÃ±o del dato.
Para datos de 100 MB, el overhead es 8Ã— el tiempo de procesamiento.
Para datos de 1 TB, el overhead es < 0.1% del tiempo total.

---

## SecciÃ³n 1.2 â€” El Problema del TamaÃ±o: Cuando los Datos No Caben

### Ejercicio 1.2.1 â€” La aritmÃ©tica del escalado

**Tipo: Calcular/razonar**

Antes de escribir cÃ³digo, vale la pena hacer la aritmÃ©tica:

```
Dato: tabla de transacciones de e-commerce.
  1 fila = 1 transacciÃ³n
  Campos: id (8B), user_id (8B), producto_id (8B), monto (8B),
          timestamp (8B), descripcion (avg 50B), regiÃ³n (4B) = ~94 bytes/fila

Volumen:
  1,000 transacciones/segundo
  = 86,400,000 transacciones/dÃ­a
  = 86,400,000 Ã— 94 bytes â‰ˆ 8 GB/dÃ­a (sin comprimir)
  = ~2.9 TB/aÃ±o (sin comprimir)
  Con Parquet (compresiÃ³n ~4:1): ~730 GB/aÃ±o
```

**Preguntas:**

1. Â¿CuÃ¡ntas filas de transacciones caben en 16 GB de RAM?
   Â¿Eso cuÃ¡ntos dÃ­as de datos representa?

2. Si quieres hacer una query sobre "transacciones del Ãºltimo aÃ±o",
   Â¿cuÃ¡ntos GB leerÃ­as en el peor caso (sin particionamiento)?
   Â¿Y con particionamiento por dÃ­a?

3. La compresiÃ³n de Parquet es ~4:1 en disco. Al leer en memoria,
   los datos se descomprimen. Â¿CuÃ¡nta RAM necesitas para procesar
   una semana de datos descomprimidos?

4. Tienes un cluster de 10 workers con 32 GB RAM cada uno.
   Â¿CuÃ¡ntos dÃ­as de datos puedes procesar en memoria simultÃ¡neamente
   (sin spill a disco)?

5. Con ese cluster, Â¿quÃ© pasa si intentas hacer un JOIN entre un aÃ±o
   de transacciones y una tabla de usuarios de 1 GB?

**Pista:** Para la pregunta 3: el factor de expansiÃ³n de Parquet en memoria
depende del tipo de dato. Para strings, puede ser 10:1 o mÃ¡s (en disco,
estÃ¡n comprimidos con dictionary encoding; en memoria, son punteros a strings completos).
Para nÃºmeros, 2:1 es mÃ¡s tÃ­pico. La prÃ¡ctica: asumir que los datos en memoria
ocupan 3-5Ã— el tamaÃ±o del archivo Parquet.

---

### Ejercicio 1.2.2 â€” Particionamiento: la soluciÃ³n al problema del tamaÃ±o

**Tipo: Leer**

El particionamiento es la tÃ©cnica fundamental para trabajar con datos
que no caben en memoria. En lugar de cargar todo, carga solo lo que necesitas.

```
Sin particionamiento:
  s3://bucket/transacciones/data.parquet  (730 GB)
  Query: "dame las transacciones de enero 2024"
  â†’ Spark debe leer los 730 GB para filtrar ~60 GB

Con particionamiento por aÃ±o/mes:
  s3://bucket/transacciones/aÃ±o=2024/mes=01/part-*.parquet  (60 GB)
  s3://bucket/transacciones/aÃ±o=2024/mes=02/part-*.parquet  (58 GB)
  ...
  Query: "dame las transacciones de enero 2024"
  â†’ Spark lee solo los 60 GB de aÃ±o=2024/mes=01/
  â†’ El resto (670 GB) ni se toca: "partition pruning"
```

La pregunta clave del particionamiento: **Â¿cuÃ¡les son las queries mÃ¡s frecuentes?**

El particionamiento Ã³ptimo para una query puede ser subÃ³ptimo para otra:

```
Particionamiento por fecha â†’ Ã³ptimo para queries por rango de fecha
Particionamiento por regiÃ³n â†’ Ã³ptimo para queries por regiÃ³n especÃ­fica
Particionamiento por (regiÃ³n, fecha) â†’ Ã³ptimo para queries que filtran ambos

No existe el "particionamiento universal".
```

**Preguntas:**

1. Para las siguientes queries, indica quÃ© particionamiento serÃ­a Ã³ptimo:
   - "Todas las transacciones de hoy"
   - "Todas las transacciones del usuario U"
   - "Todas las transacciones de mÃ¡s de $1,000 en la regiÃ³n Norte"
   - "El top 10 de productos mÃ¡s vendidos en el Ãºltimo mes"

2. Â¿Por quÃ© NO usar `user_id` como partition key si hay 10 millones de usuarios?
   (pista: nÃºmero de archivos)

3. Â¿CuÃ¡l es el "small files problem" y cÃ³mo se relaciona con el particionamiento?

4. Si una particiÃ³n tiene 500 GB y otra tiene 1 MB, Â¿quÃ© impacto tiene
   en el rendimiento de un job de Spark?

5. Un ingeniero propone: "particionemos por (aÃ±o, mes, dÃ­a, hora, regiÃ³n)
   para mÃ¡xima flexibilidad". Â¿QuÃ© problemas tiene esta propuesta?

**Pista:** Para la pregunta 2: con 10 millones de usuarios, una particiÃ³n
por `user_id` crea 10 millones de directorios en S3. El costo de listar
esos directorios puede ser mayor que el costo de leer los datos.
S3 cobra por operaciÃ³n de listing y tiene lÃ­mites de throughput por prefijo.
AdemÃ¡s, cada particiÃ³n tendrÃ­a muy pocos archivos â€” el "small files problem".

---

### Ejercicio 1.2.3 â€” Formatos de archivo: la decisiÃ³n antes del framework

**Tipo: Comparar**

El formato del archivo determina cuÃ¡nto se lee, cuÃ¡nto se comprime,
y quÃ© operaciones son eficientes â€” antes de que Spark, Polars, o cualquier
framework entre en juego.

```
CSV (texto plano, row-oriented):
  - Sin schema: cada herramienta puede inferirlo (o equivocarse)
  - Sin compresiÃ³n nativa (puede comprimirse externamente con gzip)
  - Row-oriented: para leer solo 2 columnas de 100, debes leer todas
  - Sin estadÃ­sticas: no hay forma de saber el min/max sin leer todo
  - Universal: cualquier herramienta lo puede leer
  - TamaÃ±o ejemplo (1M filas, 10 cols): ~1 GB

Parquet (binario, column-oriented):
  - Schema embebido en el archivo
  - CompresiÃ³n por columna (dict encoding, RLE, snappy/zstd)
  - Column-oriented: para leer 2 columnas de 100, solo lees esas 2
  - EstadÃ­sticas por row group: min, max, null count â†’ predicate pushdown
  - Requiere librerÃ­a para leer (pyarrow, spark, polars)
  - TamaÃ±o ejemplo (1M filas, 10 cols): ~80 MB (12:1 vs CSV)

ORC (binario, column-oriented):
  - Similar a Parquet, preferido en el ecosistema Hive/Hadoop
  - Mejor compresiÃ³n para datos con alta cardinalidad
  - Menos adoptado fuera del ecosistema Hadoop

Avro (binario, row-oriented):
  - Schema evolution: puede leer datos escritos con versiones anteriores
  - Bueno para streaming (Kafka usa Avro frecuentemente)
  - Row-oriented: no ideal para analytics
  - Bueno para: CDC, event sourcing, inter-service communication
```

**Preguntas:**

1. Una query necesita leer solo la columna `monto` de un archivo con 50 columnas.
   Â¿CuÃ¡ntos bytes lee en CSV vs Parquet (orden de magnitud)?

2. Â¿QuÃ© es el "predicate pushdown" y cÃ³mo lo habilitan las estadÃ­sticas de Parquet?

3. Si tienes datos de sensores IoT que llegan por Kafka,
   Â¿quÃ© formato usarÃ­as para: (a) transportar los datos por Kafka,
   (b) almacenarlos en S3 para analytics?

4. Â¿Por quÃ© el column-oriented es mejor para analytics pero el row-oriented
   es mejor para transacciones (bases de datos OLTP)?

5. Tienes 10 TB de CSV histÃ³rico que quieres migrar a Parquet.
   Â¿CuÃ¡nto espacio ahorras? Â¿QuÃ© ganas en velocidad de lectura?

**Pista:** Para la pregunta 4: las bases de datos OLTP (PostgreSQL, MySQL) son
row-oriented porque la operaciÃ³n mÃ¡s frecuente es leer o escribir una fila completa
("dame todos los campos del usuario 12345"). Las bases de datos analÃ­ticas son
column-oriented porque la operaciÃ³n frecuente es agregar una columna sobre
muchas filas ("el promedio de monto de todas las transacciones").
En column-oriented, esta query lee solo la columna `monto`, no todas las columnas.

> ğŸ“– Profundizar: el paper *Dremel: Interactive Analysis of Web-Scale Datasets*
> (Melnik et al., Google, 2010) explica el modelo de datos columnar anidado
> que inspirÃ³ Parquet. Es corto (~10 pÃ¡ginas) y explica por quÃ© la codificaciÃ³n
> de estructuras anidadas en columnar es mÃ¡s compleja de lo que parece.

---

### Ejercicio 1.2.4 â€” Leer: diagnosticar un pipeline lento por formato

**Tipo: Diagnosticar**

Un data engineer reporta que su job de Spark tarda 45 minutos
cuando esperaba 5 minutos. El cÃ³digo:

```python
df = spark.read.csv("s3://bucket/ventas/*.csv.gz")  # 500 GB comprimidos

resultado = (df
    .filter(df["_c3"] == "norte")      # columna 3 = regiÃ³n
    .filter(df["_c4"].cast("double") > 1000)  # columna 4 = monto
    .groupBy("_c2")                    # columna 2 = producto
    .count()
)

resultado.write.parquet("s3://bucket/resultado/")
```

MÃ©tricas del job en Spark UI:
```
Stage 0: Read CSV
  Input: 500 GB
  Output: 500 GB
  Duration: 38 min

Stage 1: Filter + GroupBy
  Input: 500 GB
  Output: 2 MB
  Duration: 5 min

Stage 2: Write Parquet
  Input: 2 MB
  Duration: 2 min
```

**Preguntas:**

1. Â¿Por quÃ© el Stage 0 lee 500 GB si el resultado final es 2 MB?

2. El archivo estÃ¡ comprimido con gzip (`.csv.gz`).
   Â¿Por quÃ© esto es un problema especÃ­fico para Spark (no para otras herramientas)?

3. Â¿El filtro `regiÃ³n == "norte"` se aplica durante la lectura del CSV?
   Â¿Por quÃ© no?

4. Si los mismos datos estuvieran en Parquet, particionado por regiÃ³n,
   Â¿cuÃ¡ntos GB leerÃ­a el Stage 0?

5. PropÃ³n tres cambios al pipeline que reducirÃ­an el tiempo de 45 a ~5 minutos.

**Pista:** `.csv.gz` (gzip sobre CSV) es un formato que Spark no puede dividir
en particiones. El archivo completo debe leerse por un solo worker antes de
distribuirlo. Gzip no es "splittable". Parquet sÃ­ es splittable â€” mÃºltiples
workers pueden leer diferentes row groups del mismo archivo en paralelo.
Para CSV comprimido que sÃ­ es splittable, usar bzip2 (pero es mÃ¡s lento para comprimir/descomprimir)
o, mejor, migrar a Parquet.

---

### Ejercicio 1.2.5 â€” El cÃ¡lculo de "cuÃ¡nto cluster necesito"

**Tipo: DiseÃ±ar/calcular**

Antes de lanzar un cluster de Spark, vale la pena estimar el tamaÃ±o necesario.
Para el siguiente workload, calcular los requerimientos mÃ­nimos:

```
Workload:
  Dataset: 3 TB de datos de transacciones en Parquet (particionado por dÃ­a)
  Job: JOIN entre transacciones y una tabla de clientes (50 GB),
       luego GROUP BY cliente + mes, SUM(monto)
  SLA: el job debe completarse en menos de 30 minutos
  Frecuencia: una vez al dÃ­a
```

Usando estas reglas prÃ¡cticas:
- TamaÃ±o de particiÃ³n Ã³ptimo: 128â€“256 MB
- Overhead de Spark en memoria: ~3Ã— el tamaÃ±o de datos procesados simultÃ¡neamente
- Throughput de procesamiento de Spark: ~100 GB/hora por core (estimaciÃ³n conservadora)

Calcular:
1. NÃºmero de particiones para el dataset de 3 TB
2. NÃºmero de cores necesarios para completar en 30 minutos
3. Memoria RAM por executor (asumiendo executors de 5 cores)
4. NÃºmero de mÃ¡quinas (asumiendo VMs de 16 cores, 64 GB RAM)
5. Â¿CÃ³mo cambia el cÃ¡lculo si el JOIN con la tabla de 50 GB
   puede hacerse con broadcast?

**Pista:** Los cÃ¡lculos de sizing son estimaciones, no garantÃ­as. Los factores
que los hacen imprecisos: data skew (algunas particiones tardan mÃ¡s),
overhead del shuffle (el JOIN genera trÃ¡fico de red), y la naturaleza
del dato (columnas de texto comprimen mucho mÃ¡s que columnas numÃ©ricas).
El approach prÃ¡ctico: estimar, lanzar un cluster, medir, ajustar.
Los proveedores cloud permiten escalar el cluster sin reescribir el job.

---

## SecciÃ³n 1.3 â€” El Problema del Tiempo: Cuando los Datos No Terminan

### Ejercicio 1.3.1 â€” Leer: batch vs streaming como decisiÃ³n de negocio

**Tipo: Analizar**

La elecciÃ³n entre batch y streaming no es solo tÃ©cnica â€” es una decisiÃ³n
sobre quÃ© pregunta estÃ¡s respondiendo.

```
Pregunta batch: "Â¿CuÃ¡nto vendimos el mes pasado?"
  Los datos son finitos (el mes pasado ya terminÃ³).
  Puedes esperar â€” el resultado se necesita maÃ±ana, no en 1 segundo.
  La correcciÃ³n importa mÃ¡s que la velocidad.
  Si el job falla, lo vuelves a correr.

Pregunta streaming: "Â¿Estamos vendiendo bien AHORA MISMO?"
  Los datos llegan continuamente â€” no hay un "final".
  El valor del resultado decae con el tiempo: saber que el sistema
  estÃ¡ caÃ­do hace 2 horas es menos Ãºtil que saberlo en 30 segundos.
  La latencia importa tanto como la correcciÃ³n.
  Si el job falla, los datos siguen llegando â€” necesitas recuperarte.
```

**Preguntas:**

Para cada una de las siguientes preguntas de negocio, determina:
- Â¿Batch o streaming?
- Â¿CuÃ¡l es la latencia aceptable?
- Â¿QuÃ© pasa si el sistema falla 10 minutos?

```
1. "Â¿CuÃ¡l fue el producto mÃ¡s vendido en Q3 2023?"
2. "Â¿Hay alguna transacciÃ³n que parece fraude en este momento?"
3. "Â¿CuÃ¡ntos usuarios activos tenemos hoy?"
4. "Â¿QuÃ© productos deberÃ­a recomendar al usuario que estÃ¡ viendo
    la pÃ¡gina ahora mismo?"
5. "Â¿CuÃ¡l es la tasa de conversiÃ³n de este experimento A/B
    que lanzamos hace 2 semanas?"
6. "Â¿El servidor de pagos estÃ¡ respondiendo con alta latencia?"
7. "Â¿CuÃ¡nto revenue generamos en el Ãºltimo aÃ±o, por paÃ­s?"
8. "Â¿CuÃ¡ntos usuarios se registraron en los Ãºltimos 5 minutos?"
```

**Pista:** Algunas preguntas tienen respuesta obvia (1 y 7 son claramente batch;
2 y 6 son claramente streaming). Las mÃ¡s interesantes son las del medio:
la pregunta 3 ("usuarios activos hoy") podrÃ­a responderse con batch si "hoy"
significa "hasta el cierre del dÃ­a", o con streaming si significa "ahora mismo".
La pregunta 4 (recomendaciones en tiempo real) parece streaming pero el modelo
de recomendaciones frecuentemente se recalcula en batch â€” solo la consulta final
es en tiempo real.

---

### Ejercicio 1.3.2 â€” El problema de los datos tardÃ­os

**Tipo: Leer**

Este es el problema mÃ¡s importante y especÃ­fico del streaming:

```
SituaciÃ³n: procesas eventos de clicks de usuarios.
Cada evento tiene un timestamp (cuÃ¡ndo ocurriÃ³ el click).

El sistema recibe los eventos en este orden:

Processing time (cuÃ¡ndo llega al sistema):
  14:00:01 â†’ click del usuario A (event time: 14:00:00)
  14:00:03 â†’ click del usuario B (event time: 14:00:02)
  14:00:15 â†’ click del usuario C (event time: 14:00:14)
  14:00:47 â†’ click del usuario D (event time: 13:59:58) â† !! llegÃ³ 49s tarde
  14:01:02 â†’ click del usuario E (event time: 14:00:59)
  14:01:58 â†’ click del usuario F (event time: 13:59:45) â† !! llegÃ³ 2m 13s tarde
```

Si calculas "clicks en la ventana 14:00â€“14:01":
- Con processing-time: incluyes todos los eventos que llegaron entre 14:00 y 14:01
  (A, B, C) â€” fÃ¡cil, pero incorrecto: D y F ocurrieron antes de 14:01 pero no se incluyen
- Con event-time: incluyes todos los eventos que OCURRIERON entre 14:00 y 14:01
  (A, B, C, D, F) â€” correcto, pero Â¿cuÃ¡ndo "cierras" la ventana?

```
El dilema:
  Si cierras la ventana a las 14:01 (processing-time):
    Pierdes D y F que llegan despuÃ©s pero ocurrieron antes.
  
  Si esperas para siempre por todos los tardÃ­os:
    El resultado nunca llega.
  
  Si esperas 5 minutos:
    El resultado llega a las 14:06 â€” 5 minutos de latencia.
    Y aÃºn asÃ­ podrÃ­as perder eventos que tardan mÃ¡s de 5 minutos.
```

**Preguntas:**

1. Â¿Por quÃ© los eventos llegan tarde? PropÃ³n tres causas tÃ©cnicas reales.

2. Para cada una de estas aplicaciones, determina cuÃ¡nto tiempo de espera
   por datos tardÃ­os es razonable:
   - DetecciÃ³n de fraude en pagos
   - Analytics de uso de una aplicaciÃ³n mÃ³vil
   - Monitoreo de infraestructura (CPU, latencia)
   - Revenue reporting para el equipo de finanzas

3. Â¿QuÃ© es un "watermark" en el contexto de stream processing?
   (No se espera conocimiento previo â€” razonar desde el problema.)

4. Si un evento llega 3 dÃ­as tarde (por ejemplo, un dispositivo mÃ³vil
   que estuvo sin conexiÃ³n 3 dÃ­as), Â¿dÃ³nde deberÃ­a "ir" ese evento?

5. Â¿El problema de los datos tardÃ­os existe en batch processing?
   Â¿O es exclusivo del streaming?

**Pista:** Para la pregunta 3: un watermark es esencialmente una declaraciÃ³n
de "todos los eventos con timestamp anterior a T ya llegaron".
Es un compromiso entre completitud (esperar a todos) y latencia (emitir pronto).
Los sistemas de streaming concretos (Beam, Flink, Spark Streaming) tienen
mecanismos para configurar este watermark â€” los veremos en los Cap.10â€“12.

---

### Ejercicio 1.3.3 â€” Micro-batching: el puente entre batch y streaming

**Tipo: Leer**

Spark Structured Streaming usa micro-batching: en lugar de procesar
evento a evento (streaming puro), procesa pequeÃ±os batches continuamente.

```
Streaming puro (Flink, Kafka Streams):
  Evento 1 llega â†’ procesar Evento 1 â†’ resultado
  Evento 2 llega â†’ procesar Evento 2 â†’ resultado
  ...
  Latencia: milisegundos por evento
  Throughput: limitado por la latencia de cada evento

Micro-batching (Spark Structured Streaming):
  Eventos 1â€“1000 llegan â†’ procesar 1000 eventos â†’ resultado
  Eventos 1001â€“2000 llegan â†’ procesar 1000 eventos â†’ resultado
  ...
  Latencia: el tamaÃ±o del micro-batch (tÃ­picamente 100msâ€“1s)
  Throughput: mÃ¡s alto (procesamiento en batch es mÃ¡s eficiente)
```

```python
# Configurar el trigger en Spark Structured Streaming:

# Trigger cada 10 segundos (micro-batch):
query = df.writeStream.trigger(processingTime='10 seconds').start()

# Trigger continuo (intenta latencia baja, experimental):
query = df.writeStream.trigger(continuous='1 second').start()

# Trigger una vez (procesar lo que hay ahora y parar):
query = df.writeStream.trigger(once=True).start()
```

**Preguntas:**

1. Si el micro-batch interval es 10 segundos y llegan 10,000 eventos/segundo,
   Â¿cuÃ¡ntos eventos procesa cada micro-batch?

2. Â¿CuÃ¡l es la latencia mÃ­nima posible con micro-batching de 10 segundos?
   (el tiempo entre que un evento llega y el resultado estÃ¡ disponible)

3. Â¿Para quÃ© caso de uso preferirÃ­as streaming puro (Flink) sobre
   micro-batching (Spark)?

4. Â¿Para quÃ© caso de uso preferirÃ­as micro-batching sobre streaming puro?

5. Si el micro-batch tarda mÃ¡s en procesarse que el interval configurado,
   Â¿quÃ© pasa? Â¿QuÃ© pasa con los eventos que siguen llegando?

**Pista:** Para la pregunta 5: si el procesamiento tarda mÃ¡s que el interval,
Spark simplemente ejecuta el siguiente micro-batch en cuanto termina el anterior.
No hay un mecanismo que reduzca la frecuencia automÃ¡ticamente. Los eventos que
llegan mientras se procesa el micro-batch anterior se acumulan en Kafka
(o en el buffer de la fuente). Esto causa "consumer lag" â€” el primer sÃ­ntoma
de que el sistema no puede mantener el ritmo de llegada de datos.

---

### Ejercicio 1.3.4 â€” El estado en streaming: el problema que no tiene batch

**Tipo: Leer**

En batch processing, el "estado" es trivial: los datos estÃ¡n en un archivo,
los lees, los procesas, los escribes. El estado entre runs estÃ¡ en los archivos.

En streaming, necesitas mantener estado entre eventos que llegan en el tiempo:

```
Query: "nÃºmero de compras por usuario en las Ãºltimas 24 horas"

En batch: fÃ¡cil.
  df.filter(fecha > hace_24h).groupBy("user_id").count()
  Los datos estÃ¡n todos en el archivo.

En streaming: Â¿cÃ³mo mantienes el conteo?
  Evento: usuario A compra a las 14:00
  Evento: usuario A compra a las 15:30
  Evento: usuario A compra a las 16:00
  
  En cada momento necesitas saber: "Â¿cuÃ¡ntas veces comprÃ³ A en las Ãºltimas 24h?"
  Esto requiere recordar las compras anteriores de A.
  
  El "estado" = la memoria de eventos pasados que afectan a eventos futuros.
```

**Preguntas:**

1. Para la query "nÃºmero de compras en las Ãºltimas 24 horas",
   Â¿quÃ© informaciÃ³n mÃ­nima necesitas guardar en el estado?

2. Â¿CuÃ¡nto crece el estado si tienes 10 millones de usuarios activos?

3. Â¿QuÃ© pasa con el estado de un usuario que lleva 6 meses sin comprar?
   Â¿DeberÃ­a permanecer en el estado indefinidamente?

4. Si el sistema de streaming falla y reinicia, Â¿quÃ© pasa con el estado?
   Â¿CÃ³mo lo recuperas?

5. En batch, si el job falla, simplemente lo vuelves a ejecutar.
   Â¿Por quÃ© es mÃ¡s complicado "volver a ejecutar" en streaming?

**Pista:** El estado en streaming es el recurso mÃ¡s crÃ­tico.
Sin gestiÃ³n del estado, el sistema eventualmente se queda sin memoria â€”
el estado acumula todas las compras de todos los usuarios desde el inicio.
Los frameworks modernos (Flink, Beam, Spark Streaming) tienen mecanismos
de "state TTL": el estado de un usuario que no ha tenido actividad en N dÃ­as
se elimina automÃ¡ticamente. TambiÃ©n tienen checkpointing: guardar el estado
periÃ³dicamente para poder recuperarlo ante un fallo.

---

### Ejercicio 1.3.5 â€” DiseÃ±ar: el mismo pipeline en batch y en streaming

**Tipo: DiseÃ±ar**

El sistema de e-commerce necesita calcular, por producto:
- NÃºmero de vistas en el Ãºltimo dÃ­a
- NÃºmero de compras en el Ãºltimo dÃ­a
- Tasa de conversiÃ³n (compras / vistas)

DiseÃ±ar dos versiones del pipeline:

**VersiÃ³n batch:**
- Frecuencia: una vez por hora
- Latencia aceptable: los datos del reporte tienen hasta 1 hora de antigÃ¼edad
- Los datos viven en S3 como archivos Parquet, particionados por hora

**VersiÃ³n streaming:**
- Latencia aceptable: el dashboard se actualiza cada 5 minutos
- Los datos llegan como eventos de Kafka en tiempo real
- Los datos tardÃ­os son posibles (hasta 10 minutos)

Para cada versiÃ³n, especificar:
1. La fuente de datos y cÃ³mo se lee
2. CÃ³mo se calcula el "Ãºltimo dÃ­a" (rolling window vs fixed window)
3. DÃ³nde y cÃ³mo se guarda el estado (para la versiÃ³n streaming)
4. QuÃ© pasa si el pipeline falla 2 horas
5. La herramienta recomendada

**Pista:** El "Ãºltimo dÃ­a" es mÃ¡s simple en batch (siempre es las Ãºltimas 24h desde ahora)
que en streaming. En streaming, una "sliding window de 24 horas que avanza cada 5 minutos"
requiere mantener en estado todos los eventos de las Ãºltimas 24 horas â€” un estado muy grande.
La alternativa prÃ¡ctica: calcular el acumulado del dÃ­a (desde medianoche) â€” un estado
mÃ¡s pequeÃ±o que se reinicia a medianoche.

---

## SecciÃ³n 1.4 â€” El Tradeoff Central: Latencia vs Throughput

### Ejercicio 1.4.1 â€” Medir: el tradeoff con nÃºmeros reales

**Tipo: Medir**

El tradeoff latencia/throughput se puede medir directamente.
Para el mismo job de suma de columnas sobre un DataFrame de 10M filas:

```python
import polars as pl
import time

df = pl.DataFrame({"valor": range(10_000_000)})

# Enfoque 1: procesar una fila a la vez (mÃ¡xima latencia, mÃ­nimo throughput)
def sumar_fila_a_fila(df):
    total = 0
    for row in df.iter_rows():
        total += row[0]
    return total

# Enfoque 2: procesar en batches de 1000 (balance)
def sumar_en_batches(df, batch_size=1000):
    total = 0
    for i in range(0, len(df), batch_size):
        batch = df[i:i+batch_size]
        total += batch["valor"].sum()
    return total

# Enfoque 3: procesar todo de una vez (mÃ¡ximo throughput, latencia del total)
def sumar_vectorizado(df):
    return df["valor"].sum()
```

**Restricciones:**
1. Medir el tiempo de cada enfoque para 10M filas
2. Calcular el throughput (filas/segundo) de cada enfoque
3. Calcular la "latencia hasta el primer resultado parcial" de cada enfoque
4. Graficar el tradeoff: eje X = latencia, eje Y = throughput

**Pista:** La latencia del enfoque 1 para el primer resultado es 0 (procesa
una fila y ya tiene un resultado parcial). La latencia del enfoque 3 para
el primer resultado es el tiempo total del job (no hay resultados parciales).
Este es exactamente el tradeoff entre streaming puro (bajo latencia, procesa
evento a evento) y batch (alto throughput, procesa todo de una vez).

---

### Ejercicio 1.4.2 â€” El tradeoff en los frameworks

**Tipo: Analizar**

Cada framework de este repositorio elige una posiciÃ³n diferente en el
espectro latencia/throughput. Completar la tabla con los valores
aproximados y justificar:

```
Framework               Latencia tÃ­pica    Throughput tÃ­pico    Overhead fijo
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Pandas (local)          ???                ???                  muy bajo
Polars (local)          ???                ???                  muy bajo
Spark (local mode)      ???                ???                  ???
Spark (cluster)         ???                ???                  ???
Kafka Streams           ???                ???                  ???
Spark Structured        ???                ???                  ???
  Streaming
Apache Flink            ???                ???                  ???
Apache Beam / Flink     ???                ???                  ???
```

Donde:
- "Latencia tÃ­pica" = tiempo entre que un dato estÃ¡ disponible y el resultado
- "Throughput tÃ­pico" = GB/hora que puede procesar por core
- "Overhead fijo" = tiempo de arranque antes de empezar a procesar

**Pista:** Los frameworks de streaming puro (Flink, Kafka Streams) tienen
baja latencia pero mÃ¡s overhead de estado y coordinaciÃ³n que batch.
Spark tiene alto overhead fijo (arranque de la JVM y el SparkSession) pero
alto throughput una vez que arrancÃ³. Polars tiene overhead mÃ­nimo y throughput
muy alto para datos que caben en memoria, pero no escala a mÃºltiples mÃ¡quinas.

---

### Ejercicio 1.4.3 â€” Leer: el sistema que eligiÃ³ el tradeoff incorrecto

**Tipo: Diagnosticar**

El equipo de un banco implementÃ³ detecciÃ³n de fraude con Spark batch:

```python
# Corre cada 15 minutos
df_transacciones = spark.read.parquet("s3://transacciones/")
df_fraude = detectar_fraude(df_transacciones)
df_fraude.write.parquet("s3://alertas-fraude/")
# Tiempo de ejecuciÃ³n: 12 minutos
```

El director de seguridad pregunta:
"Â¿Por quÃ© el banco tardÃ³ 14 minutos en detectar que la tarjeta de Juan
estaba siendo usada fraudulentamente esta maÃ±ana? Para entonces ya se
habÃ­an procesado 7 transacciones fraudulentas por un total de $4,200."

**Preguntas:**

1. Â¿Por quÃ© el sistema tardÃ³ hasta 14 minutos en detectar el fraude?
   (no 12 ni 15, sino hasta 14)

2. Â¿El tiempo de detecciÃ³n depende de cuÃ¡ndo ocurre la transacciÃ³n
   dentro del ciclo de 15 minutos?

3. Â¿CuÃ¡l es el tiempo promedio de detecciÃ³n con este diseÃ±o?

4. Â¿QuÃ© cambio en la arquitectura reducirÃ­a el tiempo de detecciÃ³n
   a menos de 30 segundos?

5. Â¿Ese cambio tiene un costo? Â¿CuÃ¡l?

**Pista:** El tiempo mÃ¡ximo de detecciÃ³n con batch de 15 minutos y 12 minutos
de procesamiento es: la transacciÃ³n ocurre justo despuÃ©s de que arranca un batch
(momento 0), el batch no la incluye (ya empezÃ³ a correr), el prÃ³ximo batch
empieza a los 15 minutos, y termina a los 27 minutos. Pero el batch que sÃ­
la incluye dura 12 minutos â†’ la alerta llega a los 15+12=27 minutos en el
peor caso. El caso mÃ¡s tÃ­pico es ~15+12/2 = ~21 minutos. Algo no cuadra con
el enunciado de 14 minutos â€” Â¿puedes explicar cÃ³mo podrÃ­a ser 14?

---

### Ejercicio 1.4.4 â€” El costo de la consistencia en streaming

**Tipo: Leer**

En streaming, hay un tradeoff adicional: consistencia de los resultados.

```
At-most-once (puede perder datos):
  El procesador recibe el evento, procesa, luego confirma la recepciÃ³n.
  Si falla despuÃ©s de procesar pero antes de confirmar â†’ el evento se pierde.
  Ventaja: sin overhead de deduplicaciÃ³n.
  CuÃ¡ndo es aceptable: mÃ©tricas donde perder el 0.1% de eventos es aceptable.

At-least-once (puede duplicar datos):
  El procesador confirma la recepciÃ³n, luego procesa.
  Si falla despuÃ©s de confirmar pero antes de procesar â†’ el evento se repite.
  La mayorÃ­a de los frameworks garantizan esto por defecto.
  CuÃ¡ndo es problemÃ¡tico: operaciones no idempotentes (cobrar una tarjeta).

Exactly-once (sin pÃ©rdida ni duplicaciÃ³n):
  El procesamiento y la confirmaciÃ³n son atÃ³micos.
  Requiere checkpointing del estado + sinks idempotentes.
  CuÃ¡ndo es necesario: transacciones financieras, inventario.
  Costo: latencia adicional (transacciÃ³n distribuida).
```

**Preguntas:**

1. Para cada caso, determina quÃ© garantÃ­a es apropiada y por quÃ©:
   - Contador de vistas de pÃ¡gina
   - Procesamiento de pagos con tarjeta
   - Pipeline de logs para debugging
   - ActualizaciÃ³n de inventario (stock disponible)
   - Notificaciones push a usuarios

2. Â¿Por quÃ© "exactly-once" es difÃ­cil de garantizar cuando el sink
   (el destino de los datos) es un sistema externo (una API, una BD)?

3. Â¿"At-least-once" + "idempotencia en el sink" equivale a "exactly-once"?
   Â¿QuÃ© significa que el sink sea idempotente?

4. En Kafka, Â¿cÃ³mo se implementa el "at-least-once" a nivel del consumer?

5. Â¿QuÃ© overhead de latencia aÃ±ade "exactly-once" respecto a "at-least-once"?
   (Orden de magnitud: Â¿10%? Â¿2Ã—? Â¿10Ã—?)

**Pista:** "At-least-once + idempotencia en el sink" sÃ­ equivale a exactly-once
en cuanto al resultado final â€” si procesar el mismo evento dos veces produce
el mismo resultado que procesarlo una vez, los duplicados son inocuos.
La clave es diseÃ±ar el sink correctamente: una operaciÃ³n INSERT con UPSERT
(insertar o actualizar si ya existe) es idempotente. Un INSERT que falla si
la clave ya existe tambiÃ©n lo es (el segundo intento falla inofensivamente).

---

### Ejercicio 1.4.5 â€” DiseÃ±ar: el tradeoff para un sistema especÃ­fico

**Tipo: DiseÃ±ar**

Una plataforma de e-commerce necesita:

```
1. Recomendaciones de productos en la pÃ¡gina principal
   (el usuario estÃ¡ viendo la pÃ¡gina ahora mismo)

2. Email de "carrito abandonado" 
   (el usuario aÃ±adiÃ³ productos pero no comprÃ³, enviar email en 1 hora)

3. Reporte de revenue para el equipo de finanzas
   (revenue diario, semanal, mensual)

4. Alerta de "producto sin stock"
   (cuando el inventario llega a 0, notificar al equipo de compras)

5. Dashboard de mÃ©tricas de negocio en tiempo real
   (GMV, conversiÃ³n, usuarios activos â€” actualizado cada minuto)
```

Para cada uno, especificar:
- Batch o streaming (y si streaming, micro-batching o streaming puro)
- Latencia aceptable
- GarantÃ­a de consistencia necesaria (at-most-once, at-least-once, exactly-once)
- Herramienta recomendada del ecosistema de este repositorio

---

## SecciÃ³n 1.5 â€” El Ecosistema: QuÃ© Herramienta para QuÃ© Problema

### Ejercicio 1.5.1 â€” El mapa de decisiÃ³n

**Tipo: Leer/memorizar**

```
                    Â¿Los datos caben en una mÃ¡quina?
                              â”‚
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 SÃ­                        No
                 â”‚                         â”‚
    Â¿Necesitas SQL o DataFrame API?      Â¿Batch o Streaming?
         â”‚                                 â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
    SQL   DataFrame            Batch             Streaming
    â”‚         â”‚                  â”‚                   â”‚
  DuckDB   Polars             Spark          Â¿Latencia < 100ms?
                                                â”‚
                                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
                                       SÃ­                No
                                       â”‚                 â”‚
                                    Flink/          Spark SS /
                                  Kafka Streams     Beam/Flink

Â¿Necesitas el mismo cÃ³digo para batch Y streaming?
  â†’ Apache Beam

Â¿Los datos viven en un lakehouse (Delta/Iceberg)?
  â†’ Spark (integraciÃ³n mÃ¡s madura)

Â¿El equipo conoce Rust y la eficiencia es crÃ­tica?
  â†’ Polars / DataFusion
```

**Preguntas:**

1. Siguiendo el Ã¡rbol de decisiÃ³n, Â¿quÃ© herramienta elegirÃ­a para:
   - 500 GB de Parquet, query SQL ad-hoc desde un notebook
   - 10 TB de eventos en Kafka, calcular mÃ©tricas cada minuto
   - 100 GB de CSV, transformaciÃ³n compleja, equipo conoce PySpark
   - 2 TB en Delta Lake, join complejo, escribe a Delta Lake

2. Â¿Hay casos donde el Ã¡rbol lleva a la herramienta equivocada?
   Â¿CuÃ¡les son sus limitaciones?

3. "Los datos caben en una mÃ¡quina" depende de cuÃ¡nta RAM tiene la mÃ¡quina.
   Una mÃ¡quina de 1 TB de RAM cambia el Ã¡rbol. Â¿CÃ³mo?

---

### Ejercicio 1.5.2 â€” Leer: la arquitectura del sistema de e-commerce

**Tipo: Leer**

Este es el sistema que construiremos a lo largo del repositorio.
Antes de empezar, entender la arquitectura completa:

```
FUENTES DE DATOS:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  PostgreSQL: catÃ¡logo de productos (1M productos)â”‚
  â”‚  Kafka: eventos de clicks (100K/s)              â”‚
  â”‚  Kafka: eventos de compras (1K/s)               â”‚
  â”‚  API externa: tipos de cambio (actualizaciÃ³n c/hora)â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
INGESTION Y PROCESAMIENTO:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Batch (Spark + Delta Lake):                    â”‚
  â”‚    - ETL diario del catÃ¡logo PostgreSQL â†’ Delta â”‚
  â”‚    - Agregaciones histÃ³ricas                    â”‚
  â”‚                                                 â”‚
  â”‚  Streaming (Flink / Spark Streaming):           â”‚
  â”‚    - Enriquecer clicks con datos del catÃ¡logo   â”‚
  â”‚    - Detectar sesiones de usuario               â”‚
  â”‚    - MÃ©tricas por ventana de 5 minutos          â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
ALMACENAMIENTO:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Delta Lake (S3): datos histÃ³ricos y agregados  â”‚
  â”‚  Redis: mÃ©tricas en tiempo real (TTL corto)     â”‚
  â”‚  Elasticsearch: bÃºsqueda y analytics ad-hoc     â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
CONSUMIDORES:
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Dashboard de BI (Tableau / Superset)           â”‚
  â”‚  API de recomendaciones (< 50ms)                â”‚
  â”‚  Alertas de fraude (< 30s)                      â”‚
  â”‚  Reportes para finanzas (diarios)               â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Preguntas:**

1. Â¿QuÃ© parte del sistema tiene el requisito de latencia mÃ¡s estricto?
   Â¿QuÃ© herramienta es mÃ¡s adecuada para ese componente?

2. Â¿Por quÃ© el catÃ¡logo de productos va de PostgreSQL a Delta Lake
   en lugar de consultarse directamente en PostgreSQL desde Spark?

3. El tipo de cambio se actualiza cada hora. Â¿CÃ³mo se propaga
   esa actualizaciÃ³n al pipeline de streaming sin reiniciarlo?

4. Â¿Hay algÃºn componente del sistema donde el "exactly-once" es obligatorio?

5. Si el sistema de Kafka falla 2 horas, Â¿quÃ© partes del sistema
   pueden seguir funcionando? Â¿CuÃ¡les fallan?

---

### Ejercicio 1.5.3 â€” El glosario del repositorio

**Tipo: Construir**

A lo largo del repositorio se usarÃ¡n muchos tÃ©rminos tÃ©cnicos.
Antes de continuar, construir un glosario personal con definiciones
en tus propias palabras para los siguientes tÃ©rminos.
No buscar la definiciÃ³n formal â€” razonar desde lo que sabes:

```
1.  ParticiÃ³n (en el contexto de Spark)
2.  Shuffle
3.  Data skew
4.  Predicate pushdown
5.  Watermark (en streaming)
6.  Consumer lag (en Kafka)
7.  Checkpoint (en streaming)
8.  Exactly-once
9.  Event-time vs processing-time
10. Columnar format
11. Broadcast join
12. State store
13. Micro-batching
14. Compaction (en Delta Lake)
15. Schema evolution
```

DespuÃ©s de completar el repositorio, volver a este ejercicio y revisar
si las definiciones cambiaron.

---

### Ejercicio 1.5.4 â€” Conectar con el repositorio de concurrencia

**Tipo: Analizar**

El repositorio de concurrencia cubriÃ³ estos conceptos. Para cada uno,
describe cuÃ¡l es el concepto equivalente en data engineering y cÃ³mo difiere:

```
1.  Goroutine leak (Cap.02 del repo de concurrencia)
    â†’ Equivalente en data engineering: ???
    â†’ Diferencia clave: ???

2.  Race condition en un mapa compartido (Cap.04)
    â†’ Equivalente: ???
    â†’ Diferencia: ???

3.  Circuit breaker (Cap.21)
    â†’ Equivalente: ???
    â†’ Diferencia: ???

4.  Event sourcing (Cap.23)
    â†’ Equivalente: ???
    â†’ Diferencia: ???

5.  Consistent hashing (Cap.23)
    â†’ Equivalente: ???
    â†’ Diferencia: ???
```

---

### Ejercicio 1.5.5 â€” El contrato del repositorio

**Tipo: Reflexionar**

Antes de continuar, hacer explÃ­cito lo que este repositorio puede
y no puede enseÃ±ar:

**Lo que este repositorio enseÃ±a:**
- CÃ³mo diagnosticar pipelines lentos o incorrectos
- CuÃ¡ndo usar cada herramienta y por quÃ©
- Los patrones de diseÃ±o que aparecen repetidamente en data engineering
- CÃ³mo razonar sobre tradeoffs antes de escribir cÃ³digo

**Lo que este repositorio NO enseÃ±a:**
- La configuraciÃ³n especÃ­fica de tu cluster (depende del proveedor)
- Los detalles de administraciÃ³n de Kafka o Flink en producciÃ³n
- Machine learning o feature engineering (son temas propios)
- SQL avanzado (se asume conocimiento previo)

**Una pregunta abierta para cerrar el capÃ­tulo:**

Un data engineer experimentado dice:
*"El 80% de los problemas de rendimiento que he visto en producciÃ³n
son una de estas tres cosas: data skew, shuffles innecesarios, o formatos
de archivo incorrectos. Si dominas esos tres conceptos, dominas la mayorÃ­a
de los problemas reales."*

Â¿EstÃ¡s de acuerdo con esa afirmaciÃ³n?
Â¿QuÃ© problema de rendimiento crees que falta en esa lista?

---

## Resumen del capÃ­tulo

**Los tres cambios de mentalidad que hace falta interiorizar:**

```
1. De control a descripciÃ³n
   En concurrencia: tÃº controlas el paralelismo.
   En data engineering: describes quÃ© quieres, el framework decide cÃ³mo.
   El error mÃ¡s comÃºn: intentar controlar el paralelismo de Spark manualmente.

2. De memoria a escala
   Los datos no caben en memoria â€” ni en la de una mÃ¡quina ni en la del cluster.
   El particionamiento es la soluciÃ³n: procesar solo los datos que necesitas.
   El formato es la fundaciÃ³n: Parquet + particionamiento = 80% de los problemas resueltos.

3. De finito a continuo
   En batch: los datos tienen un principio y un final.
   En streaming: los datos llegan continuamente, y pueden llegar tarde.
   El tradeoff es inevitable: mÃ¡s latencia = resultados mÃ¡s completos.
```

**La pregunta para evaluar cualquier decisiÃ³n de arquitectura:**

> Â¿CuÃ¡nta latencia estoy dispuesto a pagar por cuÃ¡nta completitud de datos?

Esa pregunta tiene respuestas diferentes para cada componente de un sistema.
Los siguientes 19 capÃ­tulos exploran las herramientas que corresponden
a distintas respuestas de esa pregunta.
