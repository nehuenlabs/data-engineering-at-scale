# data-engineering-at-scale

> GuÃ­a de ejercicios para procesar datos a escala â€” desde una mÃ¡quina hasta
> clusters distribuidos, desde batch hasta streaming en tiempo real.

Este repositorio es el complemento prÃ¡ctico de
[concurrencia](../concurrencia/README.md).
Donde ese repo pregunta *Â¿cÃ³mo coordino la ejecuciÃ³n concurrente?*,
este pregunta *Â¿cÃ³mo proceso datos que no caben en una mÃ¡quina,
o que no dejan de llegar?*

---

## La pregunta que organiza todo

En data engineering hay exactamente **un tradeoff central** que se repite
en cada herramienta, cada decisiÃ³n de arquitectura, y cada incidente de producciÃ³n:

```
Latencia  â†â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â†’  Throughput

Procesar cada evento en 10ms       Procesar 10 TB en 2 horas
requiere sacrificar throughput.    requiere sacrificar latencia.
```

Todos los frameworks de este repositorio son posiciones distintas en ese espectro:

```
Polars / DataFusion          Kafka Streams        Apache Flink
(batch, una mÃ¡quina,    (streaming embebido,   (streaming distribuido,
 mÃ¡xima eficiencia)      baja latencia)         estado complejo)

        Apache Spark                 Apache Beam
  (batch y micro-batch,        (modelo unificado,
   ecosistema completo)         portable entre runners)
```

Entender dÃ³nde estÃ¡ cada herramienta en ese espectro â€”
y por quÃ© estÃ¡ ahÃ­ â€” es el objetivo de este repositorio.

---

## Prerequisitos

Este repositorio asume que dominas los conceptos de:

- **Concurrencia** â€” goroutines, canales, locks, races, deadlocks.
  Si no, el [repo de concurrencia](../concurrencia/README.md)
  es el punto de partida.

- **Python bÃ¡sico** â€” los ejercicios usan Python como lenguaje principal.
  Los capÃ­tulos de lenguajes (Parte 4) cubren Java, Scala, y Rust
  en el contexto de data engineering.

- **SQL** â€” las queries de los ejercicios asumen familiaridad con
  SELECT, GROUP BY, JOIN, y window functions bÃ¡sicas.

---

## CÃ³mo usar este repositorio

Cada ejercicio tiene un **tipo** que indica quÃ© se espera:

```
Implementar   â†’  escribir cÃ³digo desde cero o completar un skeleton
Leer          â†’  analizar cÃ³digo o mÃ©tricas dado y responder preguntas
Diagnosticar  â†’  dado un sÃ­ntoma (log, dashboard, error), encontrar la causa
DiseÃ±ar       â†’  proponer una arquitectura o estrategia, justificarla
Medir         â†’  ejecutar un experimento y analizar los resultados
Comparar      â†’  evaluar dos o mÃ¡s approaches con criterios explÃ­citos
```

Los ejercicios de tipo **Leer** y **Diagnosticar** son tan importantes
como los de **Implementar**. En producciÃ³n, la mayorÃ­a del tiempo
se pasa diagnosticando pipelines lentos o incorrectos â€” no escribiendo
cÃ³digo nuevo.

### Referencias en los ejercicios

A lo largo del repositorio encontrarÃ¡s tres tipos de notas:

```
> ðŸ“– Profundizar: â€” paper o libro que es la fuente canÃ³nica del concepto.

> âš™ï¸ VersiÃ³n: â€” cuando el comportamiento depende de la versiÃ³n exacta
               del framework o de la configuraciÃ³n del cluster.

> ðŸ”— Ecosistema: â€” herramienta relacionada relevante en producciÃ³n
                  que no se cubre en profundidad aquÃ­.
```

---

## Estructura del repositorio

```
Parte 1 â€” El modelo mental (Cap.01â€“03)
  Fundamentos compartidos por todos los frameworks.
  Sin entender estos tres capÃ­tulos, los demÃ¡s no tienen contexto.

Parte 2 â€” Batch processing (Cap.04â€“08)
  Procesar datos que ya existen â€” archivos, bases de datos, objetos en S3.

Parte 3 â€” Stream processing (Cap.09â€“12)
  Procesar datos que estÃ¡n llegando ahora mismo.

Parte 4 â€” Lenguajes y ecosistemas (Cap.13â€“16)
  El mismo problema visto desde Python, Java/Scala, y Rust.

Parte 5 â€” En producciÃ³n (Cap.17â€“20)
  Orquestar, observar, testear, y mantener pipelines de datos.
```

---

## Tabla de capÃ­tulos

### Parte 1 â€” El modelo mental

| Cap. | TÃ­tulo | DescripciÃ³n |
|------|--------|-------------|
| 01 | [De concurrencia a datos distribuidos](01_de_concurrencia_a_datos.md) | El puente conceptual. Por quÃ© los frameworks de datos invierten el modelo de concurrencia. |
| 02 | [Formatos y representaciÃ³n en memoria](02_formatos_y_memoria.md) | Row vs columnar, Apache Arrow, Parquet, compresiÃ³n. La base que todos los frameworks comparten. |
| 03 | [El modelo Map/Reduce](03_mapreduce.md) | No como tecnologÃ­a sino como paradigma. La abstracciÃ³n que subyace a Spark, Beam, y Hadoop. |

### Parte 2 â€” Batch processing

| Cap. | TÃ­tulo | DescripciÃ³n |
|------|--------|-------------|
| 04 | [Spark â€” modelo de ejecuciÃ³n y diagnÃ³stico](04_spark_modelo_ejecucion.md) | DAG, stages, shuffles, Spark UI. CÃ³mo Spark planifica y ejecuta el trabajo. |
| 05 | [Spark â€” optimizaciÃ³n avanzada](05_spark_optimizacion.md) | Data skew, broadcast joins, AQE, cachÃ©, configuraciÃ³n de memoria. |
| 06 | [Polars â€” paralelismo sin JVM](06_polars.md) | El modelo de Rust aplicado a data frames. CuÃ¡ndo supera a Spark y cuÃ¡ndo no. |
| 07 | [DataFusion â€” SQL distribuido en Rust](07_datafusion.md) | El motor embebido. Arrow como formato unificador del ecosistema Rust. |
| 08 | [El lakehouse â€” Delta Lake, Iceberg, Hudi](08_lakehouse.md) | ACID sobre object storage. Time travel, schema evolution, upserts a escala. |

### Parte 3 â€” Stream processing

| Cap. | TÃ­tulo | DescripciÃ³n |
|------|--------|-------------|
| 09 | [Kafka â€” el log distribuido](09_kafka.md) | Productores, consumidores, particiones, offsets, consumer groups. |
| 10 | [Apache Beam â€” el modelo unificado](10_beam.md) | PCollections, DoFns, windowing, watermarks. Batch y streaming con el mismo cÃ³digo. |
| 11 | [Spark Structured Streaming](11_spark_streaming.md) | Micro-batching, triggers, foreachBatch, integraciÃ³n con Delta Lake. |
| 12 | [Flink â€” cuando Spark Streaming no es suficiente](12_flink.md) | Streaming puro, estado complejo, exactly-once, latencia < 100ms. |

### Parte 4 â€” Lenguajes y ecosistemas

| Cap. | TÃ­tulo | DescripciÃ³n |
|------|--------|-------------|
| 13 | [Python â€” PySpark, Arrow, y la GIL en data engineering](13_python.md) | UDFs, Pandas UDFs, el rol de la GIL, el ecosistema PyData. |
| 14 | [Scala â€” el lenguaje nativo de Spark](14_scala.md) | Por quÃ© Spark se escribe en Scala. Tipos, pattern matching, implicits en el contexto de datos. |
| 15 | [Java â€” Beam, Kafka Streams, ecosistema empresarial](15_java.md) | Stream processing en Java. CuÃ¡ndo la verbosidad de Java es una ventaja. |
| 16 | [Rust â€” DataFusion, Polars, Delta-rs](16_rust.md) | El ownership aplicado a data engineering. Por quÃ© Rust estÃ¡ ganando terreno en el ecosistema. |

### Parte 5 â€” En producciÃ³n

| Cap. | TÃ­tulo | DescripciÃ³n |
|------|--------|-------------|
| 17 | [OrquestaciÃ³n â€” Airflow, Dagster, Prefect](17_orquestacion.md) | DAGs de pipelines, dependencias, reintentos, backfill. |
| 18 | [Observabilidad de pipelines de datos](18_observabilidad.md) | MÃ©tricas, logs, trazabilidad de datos (data lineage), alertas. |
| 19 | [Testing de pipelines](19_testing.md) | Unit tests, integration tests, contract tests, testing de streaming. |
| 20 | [El sistema completo](20_sistema_completo.md) | Integrando todo: de la fuente de datos al dashboard, con resiliencia y observabilidad. |

---

## El hilo conductor

A lo largo del repositorio construimos el mismo sistema de ejemplo:
una **plataforma de analytics de e-commerce** con:

- Eventos de clicks y compras (streaming, Kafka)
- CatÃ¡logo de productos (batch, PostgreSQL)
- MÃ©tricas de negocio (revenue, conversiÃ³n, fraude)
- Dashboard en tiempo real y reportes histÃ³ricos

El mismo sistema se implementa incrementalmente en cada parte:
- Parte 1: entender el modelo de datos
- Parte 2: pipeline batch con Spark y Polars
- Parte 3: pipeline streaming con Kafka y Flink
- Parte 4: el mismo pipeline en distintos lenguajes
- Parte 5: el sistema completo en producciÃ³n

Al final del repositorio, tienes un sistema funcionando de principio a fin
â€” no ejercicios aislados.

---

## Lenguajes y versiones de referencia

```
Python    3.11+     (PySpark, Beam, Polars, DataFusion)
Java      17 LTS    (Beam, Kafka Streams, Flink)
Scala     2.13      (Spark nativo)
Rust      1.75+     (Polars, DataFusion, Delta-rs)

Apache Spark         3.5.x
Apache Kafka         3.6.x
Apache Beam          2.52.x
Apache Flink         1.18.x
Polars               0.20.x
Apache DataFusion    35.x
Delta Lake           3.x
```

> âš™ï¸ VersiÃ³n: los ejercicios se verificaron con las versiones listadas.
> El comportamiento de AQE (Spark), el estado en Flink, y las APIs de Polars
> cambian entre versiones menores. Antes de ejecutar en producciÃ³n,
> verificar el changelog de la versiÃ³n especÃ­fica de tu entorno.

---

## RelaciÃ³n con otros repositorios

```
concurrencia/
  â†“ prerequisito conceptual
data-engineering-at-scale/   â† este repositorio
  â†“ aplicaciÃ³n prÃ¡ctica
[algoritmos/]                (repo de algoritmos y estructuras de datos)
```

Los conceptos del repo de concurrencia que mÃ¡s aparecen aquÃ­:

| Concurrencia | Equivalente en data engineering |
|---|---|
| Goroutine / Thread | Task de Spark / Flink operator |
| Canal de Go | Kafka topic / Beam PCollection |
| Mutex / Lock | Optimistic concurrency control en Delta Lake |
| Race condition | Inconsistencia en replicaciÃ³n eventual |
| Deadlock | Shuffle deadlock en Spark (ver Cap.04) |
| Goroutine leak | Consumer lag sin lÃ­mite en Kafka (ver Cap.09) |
| Circuit breaker | Backpressure en stream processing (ver Cap.12) |

---

## Convenciones del repositorio

```python
# Los ejemplos de cÃ³digo son runnable cuando es posible.
# Los que requieren un cluster estÃ¡n marcados con:
# [REQUIERE CLUSTER] â€” necesita Spark/Flink/Kafka corriendo

# Los fragmentos de diagnÃ³stico muestran output real:
# >>> df.explain()
# == Physical Plan ==
# ...

# Las mÃ©tricas de performance son orientativas (hardware de referencia:
# laptop con 16GB RAM, 8 cores, SSD NVMe).
# Los tiempos absolutos variarÃ¡n; los relativos son representativos.
```

---

*Este repositorio se construye incrementalmente.
Cada capÃ­tulo referencia los anteriores â€” leer en orden la primera vez.*
